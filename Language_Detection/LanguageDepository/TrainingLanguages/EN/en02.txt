League of Legends received generally positive reviews; critics highlighted its accessibility, character designs, and production value. The game's long lifespan has resulted in a critical reappraisal, with reviews trending positively; the negative and abusive in-game behavior of its players, criticized since early in the game's lifetime, persists despite Riot's attempts to fix the problem. In 2019, the game regularly peaked at eight million concurrent players, and its popularity has led to tie-ins such as music videos, comic books, short stories, and an animated series, Arcane. Its success has also spawned several spin-off video games, including a mobile version, a digital collectible card game and a turn-based role-playing game, among others. A massively multiplayer online role-playing game based on the property is in development.

Regularly cited as the world's largest esport, the game has an international competitive scene consisting of 12 leagues. These domestic leagues culminate in the annual League of Legends World Championship. The 2019 event registered over 100 million unique viewers, peaking at a concurrent viewership of 44 million. Domestic and international events have been broadcast on livestreaming websites such as Twitch, YouTube, Bilibili, and on cable television sports channel ESPN.
The perceptron is a linear classifier, therefore it will never get to the state with all the input vectors classified correctly if the training set D is not linearly separable, i.e. if the positive examples cannot be separated from the negative examples by a hyperplane. In this case, no "approximate" solution will be gradually approached under the standard learning algorithm, but instead, learning will fail completely. Hence, if linear separability of the training set is not known a priori, one of the training variants below should be used.

If the training set is linearly separable, then the perceptron is guaranteed to converge.[9] Furthermore, there is an upper bound on the number of times the perceptron will adjust its weights during the training.

Suppose that the input vectors from the two classes can be separated by a hyperplane with a margin {\displaystyle \gamma }\gamma , i.e. there exists a weight vector {\displaystyle \mathbf {w} ,||\mathbf {w} ||=1}\mathbf {w} ,||\mathbf {w} ||=1, and a bias term b such that {\displaystyle \mathbf {w} \cdot \mathbf {x} _{j}>\gamma }{\displaystyle \mathbf {w} \cdot \mathbf {x} _{j}>\gamma } for all {\displaystyle j}j with {\displaystyle d_{j}=1}{\displaystyle d_{j}=1} and {\displaystyle \mathbf {w} \cdot \mathbf {x} _{j}<-\gamma }{\displaystyle \mathbf {w} \cdot \mathbf {x} _{j}<-\gamma } for all {\displaystyle j}j with {\displaystyle d_{j}=0}{\displaystyle d_{j}=0}, where {\displaystyle d_{j}}d_{j} is the desired output value of the perceptron for input {\displaystyle j}j. Also, let R denote the maximum norm of an input vector. Novikoff (1962) proved that in this case the perceptron algorithm converges after making {\displaystyle O(R^{2}/\gamma ^{2})}O(R^{2}/\gamma ^{2}) updates. The idea of the proof is that the weight vector is always adjusted by a bounded amount in a direction with which it has a negative dot product, and thus can be bounded above by O(√t), where t is the number of changes to the weight vector. However, it can also be bounded below by O(t) because if there exists an (unknown) satisfactory weight vector, then every change makes progress in this (unknown) direction by a positive amount that depends only on the input vector.


Two classes of points, and two of the infinitely many linear boundaries that separate them. Even though the boundaries are at nearly right angles to one another, the perceptron algorithm has no way of choosing between them.
While the perceptron algorithm is guaranteed to converge on some solution in the case of a linearly separable training set, it may still pick any solution and problems may admit many solutions of varying quality.[10] The perceptron of optimal stability, nowadays better known as the linear support-vector machine, was designed to solve this problem (Krauth and Mezard, 1987).[11]

Variants
The pocket algorithm with ratchet (Gallant, 1990) solves the stability problem of perceptron learning by keeping the best solution seen so far "in its pocket". The pocket algorithm then returns the solution in the pocket, rather than the last solution. It can be used also for non-separable data sets, where the aim is to find a perceptron with a small number of misclassifications. However, these solutions appear purely stochastically and hence the pocket algorithm neither approaches them gradually in the course of learning, nor are they guaranteed to show up within a given number of learning steps.

The Maxover algorithm (Wendemuth, 1995) is "robust" in the sense that it will converge regardless of (prior) knowledge of linear separability of the data set.[12] In the linearly separable case, it will solve the training problem – if desired, even with optimal stability (maximum margin between the classes). For non-separable data sets, it will return a solution with a small number of misclassifications. In all cases, the algorithm gradually approaches the solution in the course of learning, without memorizing previous states and without stochastic jumps. Convergence is to global optimality for separable data sets and to local optimality for non-separable data sets.

The Voted Perceptron (Freund and Schapire, 1999), is a variant using multiple weighted perceptrons. The algorithm starts a new perceptron every time an example is wrongly classified, initializing the weights vector with the final weights of the last perceptron. Each perceptron will also be given another weight corresponding to how many examples do they correctly classify before wrongly classifying one, and at the end the output will be a weighted vote on all perceptrons.

In separable problems, perceptron training can also aim at finding the largest separating margin between the classes. The so-called perceptron of optimal stability can be determined by means of iterative training and optimization schemes, such as the Min-Over algorithm (Krauth and Mezard, 1987)[11] or the AdaTron (Anlauf and Biehl, 1989)).[13] AdaTron uses the fact that the corresponding quadratic optimization problem is convex. The perceptron of optimal stability, together with the kernel trick, are the conceptual foundations of the support-vector machine.

The {\displaystyle \alpha }\alpha -perceptron further used a pre-processing layer of fixed random weights, with thresholded output units. This enabled the perceptron to classify analogue patterns, by projecting them into a binary space. In fact, for a projection space of sufficiently high dimension, patterns can become linearly separable.

Another way to solve nonlinear problems without using multiple layers is to use higher order networks (sigma-pi unit). In this type of network, each element in the input vector is extended with each pairwise combination of multiplied inputs (second order). This can be extended to an n-order network.

It should be kept in mind, however, that the best classifier is not necessarily that which classifies all the training data perfectly. Indeed, if we had the prior constraint that the data come from equi-variant Gaussian distributions, the linear separation in the input space is optimal, and the nonlinear solution is overfitted.

Other linear classification algorithms include Winnow, support-vector machine, and logistic regression.

Multiclass perceptron
Like most other techniques for training linear classifiers, the perceptron generalizes naturally to multiclass classification. Here, the input {\displaystyle x}x and the output {\displaystyle y}y are drawn from arbitrary sets. A feature representation function {\displaystyle f(x,y)}f(x,y) maps each possible input/output pair to a finite-dimensional real-valued feature vector. As before, the feature vector is multiplied by a weight vector {\displaystyle w}w, but now the resulting score is used to choose among many possible outputs:

{\displaystyle {\hat {y}}=\operatorname {argmax} _{y}f(x,y)\cdot w.}{\hat {y}}=\operatorname {argmax} _{y}f(x,y)\cdot w.
Learning again iterates over the examples, predicting an output for each, leaving the weights unchanged when the predicted output matches the target, and changing them when it does not. The update becomes:

{\displaystyle w_{t+1}=w_{t}+f(x,y)-f(x,{\hat {y}}).}w_{t+1}=w_{t}+f(x,y)-f(x,{\hat {y}}).
This multiclass feedback formulation reduces to the original perceptron when {\displaystyle x}x is a real-valued vector, {\displaystyle y}y is chosen from {\displaystyle \{0,1\}}\{0,1\}, and {\displaystyle f(x,y)=yx}f(x,y)=yx.

For certain problems, input/output representations and features can be chosen so that {\displaystyle \mathrm {argmax} _{y}f(x,y)\cdot w}\mathrm {argmax} _{y}f(x,y)\cdot w can be found efficiently even though {\displaystyle y}y is chosen from a very large or even infinite set.

Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002). It has also been applied to large-scale machine learning problems in a distributed computing setting.[14]